{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vqGEtKqj4qoZ4MnCLlghGkNCrbXFjxHD","authorship_tag":"ABX9TyM8/KKAKnXOYK8zUqxr/5dN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aeZq5MjTX7vQ"},"outputs":[],"source":["import os\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.applications import VGG16  # Changed from ResNet50\n","from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.regularizers import l2"]},{"cell_type":"code","source":["batch_size = 32\n","\n","input_shape = (224, 224, 3)"],"metadata":{"id":"bR7MyC0zdO_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path = '/content/drive/MyDrive/oocyte.v16i.voc'\n"],"metadata":{"id":"vbUcbhn-dO84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = os.path.join(dataset_path, 'Train')\n","test_path = os.path.join(dataset_path, 'Test')\n","valid_path = os.path.join(dataset_path, 'Valid')"],"metadata":{"id":"oYdHDDCFdO2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_images_and_labels(image_dir, label_dir):\n","    images = []\n","    labels = []\n","\n","    # List all XML files in the label directory\n","    xml_files = [filename for filename in os.listdir(label_dir) if filename.endswith('.xml')]\n","    print(\"Found XML Files:\", xml_files)\n","\n","    # Iterate over image files\n","    for image_filename in os.listdir(image_dir):\n","        if image_filename.endswith('.jpg'):\n","            image_path = os.path.join(image_dir, image_filename)\n","            label_filename = os.path.splitext(image_filename)[0] + '.xml'\n","\n","            label_path = os.path.join(label_dir, label_filename)\n","            print(\"Checking Path:\", label_path)  # Print the label path for troubleshooting\n","\n","            # Load image\n","            image = load_img(image_path, target_size=input_shape[:2])\n","            image = img_to_array(image)\n","            images.append(image)\n","\n","            if os.path.exists(label_path):\n","                # Parse XML label\n","                tree = ET.parse(label_path)\n","                root = tree.getroot()\n","                label_element = root.find('object/name')  # Find the <name> element under <object>\n","                if label_element is not None:\n","                    label = label_element.text.strip()  # Extract the label text and remove whitespace\n","                    labels.append(label)\n","                else:\n","                    labels.append(\"unknown\")  # Placeholder label for images without a label\n","            else:\n","                labels.append(\"unknown\")  # Placeholder label for images without a label\n","\n","    return np.array(images), np.array(labels)"],"metadata":{"id":"rCU-j3ABdOvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images, train_labels = load_images_and_labels(train_path, train_path)\n","test_images, test_labels = load_images_and_labels(test_path, test_path)\n","valid_images, valid_labels = load_images_and_labels(valid_path, valid_path)"],"metadata":{"id":"SJu6vUUGdbC9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_encoder = LabelEncoder()\n"],"metadata":{"id":"GeU0pNXWda-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_labels_encoded = label_encoder.fit_transform(train_labels)\n","test_labels_encoded = label_encoder.transform(test_labels)\n","valid_labels_encoded = label_encoder.transform(valid_labels)"],"metadata":{"id":"CPu03Ue7da3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = len(label_encoder.classes_)\n","train_labels_categorical = to_categorical(train_labels_encoded, num_classes)\n","test_labels_categorical = to_categorical(test_labels_encoded, num_classes)\n","valid_labels_categorical = to_categorical(valid_labels_encoded, num_classes)"],"metadata":{"id":"Hge7lRxFeYNq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)  # Changed from ResNet50\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tIOqHpxeYL6","executionInfo":{"status":"ok","timestamp":1692813666569,"user_tz":-330,"elapsed":942,"user":{"displayName":"Chinthakayala Mounika","userId":"17658252627553731903"}},"outputId":"445198c8-126a-475d-93f9-5a47e24d93a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["x = base_model.output\n","x = Flatten()(x)\n","x = Dense(512, activation='relu')(x)  # Adjusted units and added dropout\n","x = Dropout(0.5)(x)\n","predictions = Dense(num_classes, activation='softmax')(x)"],"metadata":{"id":"RO_JLeoVeYEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(inputs=base_model.input, outputs=predictions)\n"],"metadata":{"id":"pvj1xFPHeX9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"15Pv_-Eoep-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_images, train_labels_categorical, epochs=10, validation_data=(valid_images, valid_labels_categorical))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCZpO6gcep8F","executionInfo":{"status":"ok","timestamp":1692819290872,"user_tz":-330,"elapsed":5604192,"user":{"displayName":"Chinthakayala Mounika","userId":"17658252627553731903"}},"outputId":"24213530-7d3b-414b-9110-7d68873c9fd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","12/12 [==============================] - 562s 47s/step - loss: 33.9341 - accuracy: 0.5184 - val_loss: 0.8244 - val_accuracy: 0.2078\n","Epoch 2/10\n","12/12 [==============================] - 561s 47s/step - loss: 0.7315 - accuracy: 0.6374 - val_loss: 0.8952 - val_accuracy: 0.7662\n","Epoch 3/10\n","12/12 [==============================] - 549s 46s/step - loss: 0.7564 - accuracy: 0.6742 - val_loss: 0.6396 - val_accuracy: 0.7662\n","Epoch 4/10\n","12/12 [==============================] - 544s 45s/step - loss: 0.7185 - accuracy: 0.6856 - val_loss: 0.7129 - val_accuracy: 0.7662\n","Epoch 5/10\n","12/12 [==============================] - 550s 46s/step - loss: 0.7085 - accuracy: 0.6884 - val_loss: 0.5988 - val_accuracy: 0.7662\n","Epoch 6/10\n","12/12 [==============================] - 567s 47s/step - loss: 0.6647 - accuracy: 0.6969 - val_loss: 0.5943 - val_accuracy: 0.7662\n","Epoch 7/10\n","12/12 [==============================] - 561s 47s/step - loss: 0.6783 - accuracy: 0.6714 - val_loss: 0.6350 - val_accuracy: 0.7662\n","Epoch 8/10\n","12/12 [==============================] - 554s 46s/step - loss: 0.6726 - accuracy: 0.6884 - val_loss: 0.6258 - val_accuracy: 0.7662\n","Epoch 9/10\n","12/12 [==============================] - 567s 47s/step - loss: 0.6789 - accuracy: 0.6941 - val_loss: 0.6113 - val_accuracy: 0.7662\n","Epoch 10/10\n","12/12 [==============================] - 560s 47s/step - loss: 0.6580 - accuracy: 0.6827 - val_loss: 0.6614 - val_accuracy: 0.7662\n"]}]},{"cell_type":"code","source":["train_acc = history.history['accuracy'][-1]\n","print(\"Training Accuracy:\", train_acc)\n","\n","val_acc = history.history['val_accuracy'][-1]\n","print(\"Validation Accuracy:\", val_acc)\n","\n","test_loss, test_acc = model.evaluate(test_images, test_labels_categorical)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tY0SlCv2epz4","executionInfo":{"status":"ok","timestamp":1692819341017,"user_tz":-330,"elapsed":41398,"user":{"displayName":"Chinthakayala Mounika","userId":"17658252627553731903"}},"outputId":"677d9943-5ab7-4e04-d39d-14e650498d1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 0.6827195286750793\n","Validation Accuracy: 0.7662337422370911\n","3/3 [==============================] - 31s 9s/step - loss: 0.6274 - accuracy: 0.7067\n","Test Loss: 0.6273614764213562\n","Test Accuracy: 0.7066666483879089\n"]}]}]}